{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy.stats as stats \n",
    "import numpy as np\n",
    "from pandas.api.types import is_numeric_dtype\n",
    "from pandas.api.types import is_categorical_dtype\n",
    "from pandas.api.types import is_string_dtype\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hours_studied</th>\n",
       "      <th>grade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   hours_studied grade\n",
       "0              4     N\n",
       "1              5     Y\n",
       "2              9     N\n",
       "3             12     Y\n",
       "4             15     Y"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agey = pd.DataFrame({'age':pd.Series([21,22,24,25,27,27,27,35,41]), 'grade': pd.Series(list('FFPFPPPPP'))})\n",
    "agey\n",
    "\n",
    "wah = pd.DataFrame({'hours_studied': pd.Series([4,5,9,12,15]), 'grade': list('NYNYY')})\n",
    "wah\n",
    "# real = pd.read_csv(\"Datasets/diamonds.csv\")\n",
    "# real.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(234, 2)\n",
      "Info gain: 1.1019550008653873\n",
      "Boundary : 10.5\n",
      "\n",
      "Set 1\n",
      "   hours_studied grade\n",
      "0              4     N\n",
      "1              5     Y\n",
      "2              9     N\n",
      "Set 2\n",
      "   hours_studied grade\n",
      "3             12     Y\n",
      "4             15     Y\n",
      "------------------------------\n",
      "\n",
      "Info gain: 0.8\n",
      "Boundary : 4.5\n",
      "\n",
      "Set 1\n",
      "   hours_studied grade\n",
      "0              4     N\n",
      "Set 2\n",
      "   hours_studied grade\n",
      "1              5     Y\n",
      "2              9     N\n",
      "------------------------------\n",
      "\n",
      "Info gain: 0.0\n",
      "Boundary : 13.5\n",
      "\n",
      "Set 1\n",
      "   hours_studied grade\n",
      "3             12     Y\n",
      "Set 2\n",
      "   hours_studied grade\n",
      "4             15     Y\n",
      "------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def entropy_discretize(df, discretize_column, class_col ,nbins = None, threshold = None):\n",
    "    probs_df =  calculate_prob(df[discretize_column])\n",
    "    entropy_df = stats.entropy(probs_df, base=2)\n",
    "    \n",
    "    exit_cond = True\n",
    "    best_boundaries = []\n",
    "    x = [df]\n",
    "    resey = []\n",
    "    \n",
    "    while exit_cond:\n",
    "        \n",
    "        if len(resey) > 0 : \n",
    "            x[:] = resey[:]\n",
    "            resey[:] = []\n",
    "        \n",
    "        for a in x:\n",
    "            boundaries = calculate_boundaries(a, discretize_column)\n",
    "            splits = [(a.iloc[0:x+1,:], a.iloc[x+1:,:], y) for x,y in enumerate(boundaries)]\n",
    "            gains = []\n",
    "            for s1,s2, boundary in splits:\n",
    "                probs_s1 =  calculate_prob(s1[class_col])\n",
    "                probs_s2 =  calculate_prob(s2[class_col])\n",
    "                entropy_s1 = stats.entropy(probs_s1, base=2)\n",
    "                entropy_s2 = stats.entropy(probs_s2, base=2)\n",
    "                total_size = df.shape[0]\n",
    "                gains.append((info_gain(entropy_s1,entropy_s2,s1,s2,total_size) , boundary,s1, s2))\n",
    "#             print(gains)\n",
    "            max_info = min(gains,  key = lambda t: t[0])\n",
    "    \n",
    "            best_boundaries.append(max_info)\n",
    "            # took the most simplest path dunt have time for optimization\n",
    "            resey.append(max_info[2])\n",
    "            resey.append(max_info[3])\n",
    "            # stopping condition\n",
    "            if nbins:\n",
    "                if len(best_boundaries) * 2 >= nbins:\n",
    "                    exit_cond = False\n",
    "            elif threshold:\n",
    "                if entropy_df - max_info[0] > threshold :\n",
    "                    exit_cond = False\n",
    "            \n",
    "                \n",
    "    return best_boundaries\n",
    "            \n",
    "        \n",
    "\n",
    "    \n",
    "    \n",
    "#     for best_boundary in best_boundaries[:]:\n",
    "        \n",
    "    \n",
    "        \n",
    "#         boundaries = calculate_boundaries(df, discretize_column)\n",
    "#         splits = [(df.iloc[0:x+1,:], df.iloc[x+1:,:], y) for x,y in enumerate(boundaries)]\n",
    "#         gains = []\n",
    "#         for s1,s2, boundary in splits:\n",
    "#             probs_s1 =  calculate_prob(s1[discretize_column])\n",
    "#             probs_s2 =  calculate_prob(s2[discretize_column])\n",
    "#             entropy_s1 = stats.entropy(probs_s1, base=2)\n",
    "#             entropy_s2 = stats.entropy(probs_s2, base=2)\n",
    "#             total_size = df.shape[0]\n",
    "#             gains.append((info_gain(entropy_s1,entropy_s2,s1,s2,total_size) , boundary,s1, s2))\n",
    "\n",
    "         \n",
    "#         best_boundaries.append(min(gains))\n",
    "#         end_result.append(min(gains))\n",
    "#         current_bins += 1\n",
    "#         if current_bins == nbins:\n",
    "#             print(\"bin limit reached end it\")\n",
    "#             return \n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "   \n",
    "        \n",
    "# #         print(\"gain\",gain)\n",
    "#         print(\"probs1\", probs_s1)\n",
    "#         print(\"probs2\", probs_s2)\n",
    "        \n",
    "#         print(\"entropy_s1\" ,entropy_s1)\n",
    "#         print(\"entropy_s2\",entropy_s2)\n",
    "#         print(\"boundary\",boundary)\n",
    "#         print(\"s1\",s1)\n",
    "#         print(\"s2\",s2)\n",
    "#     print(gains\n",
    "#     print(f\"Current best cut is {min(gains)[1]} with gain {min(gains)[0]}\")\n",
    "#     print(\"S1\")\n",
    "#     print(min(gains)[2])\n",
    "#     print(\"S2\")\n",
    "#     print(min(gains)[3])\n",
    "#     print(best_boundaries)\n",
    "mpg =pd.read_csv(\"Datasets/mpg.csv\")\n",
    "mpg = mpg[['displ','class']]\n",
    "print(mpg.shape)\n",
    "# print(mpg.head())\n",
    "\n",
    "result = entropy_discretize(df = wah, discretize_column = 'hours_studied',class_col = 'grade', nbins = 6)\n",
    "for a,b,c,d in result:\n",
    "    print(f\"Info gain: {a}\")\n",
    "    print(f\"Boundary : {b}\")\n",
    "    print(\"\")\n",
    "    print(\"Set 1\")\n",
    "    print(c.head())\n",
    "    print(\"Set 2\")\n",
    "    print(d.head())\n",
    "    print(\"-\" * 30)\n",
    "    print(\"\")\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make boundary function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate boundaries for a continous variable\n",
    "# vectorized\n",
    "def calculate_boundaries(df = None, column = None):\n",
    "    if df is None:\n",
    "        raise ValueError(\"dataframe must not be empty\")\n",
    "    if column is None:\n",
    "        raise ValueError(\"column must not be empty\")\n",
    "    if is_numeric_dtype(df[column]) != True:\n",
    "        raise TypeError(\"column must be of numeric type\")\n",
    "\n",
    "    return pd.Series((df[column][1:].values + df[column][:-1].values) / 2, name = \"boundaries\")  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    21.5\n",
      "1    23.0\n",
      "2    24.5\n",
      "3    26.0\n",
      "4    27.0\n",
      "5    27.0\n",
      "6    31.0\n",
      "7    38.0\n",
      "Name: boundaries, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "boundaries = calculate_boundaries(agey, 'age')\n",
    "print(boundaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next Split with boundary 21.5\n",
      "------------------------------\n",
      "______________________________\n",
      "S1\n",
      "   age grade\n",
      "0   21     F\n",
      "______________________________\n",
      "S2\n",
      "   age grade\n",
      "1   22     F\n",
      "2   24     P\n",
      "3   25     F\n",
      "4   27     P\n",
      "5   27     P\n",
      "6   27     P\n",
      "7   35     P\n",
      "8   41     P\n",
      "\n",
      "\n",
      "Next Split with boundary 23.0\n",
      "------------------------------\n",
      "______________________________\n",
      "S1\n",
      "   age grade\n",
      "0   21     F\n",
      "1   22     F\n",
      "______________________________\n",
      "S2\n",
      "   age grade\n",
      "2   24     P\n",
      "3   25     F\n",
      "4   27     P\n",
      "5   27     P\n",
      "6   27     P\n",
      "7   35     P\n",
      "8   41     P\n",
      "\n",
      "\n",
      "Next Split with boundary 24.5\n",
      "------------------------------\n",
      "______________________________\n",
      "S1\n",
      "   age grade\n",
      "0   21     F\n",
      "1   22     F\n",
      "2   24     P\n",
      "______________________________\n",
      "S2\n",
      "   age grade\n",
      "3   25     F\n",
      "4   27     P\n",
      "5   27     P\n",
      "6   27     P\n",
      "7   35     P\n",
      "8   41     P\n",
      "\n",
      "\n",
      "Next Split with boundary 26.0\n",
      "------------------------------\n",
      "______________________________\n",
      "S1\n",
      "   age grade\n",
      "0   21     F\n",
      "1   22     F\n",
      "2   24     P\n",
      "3   25     F\n",
      "______________________________\n",
      "S2\n",
      "   age grade\n",
      "4   27     P\n",
      "5   27     P\n",
      "6   27     P\n",
      "7   35     P\n",
      "8   41     P\n",
      "\n",
      "\n",
      "Next Split with boundary 27.0\n",
      "------------------------------\n",
      "______________________________\n",
      "S1\n",
      "   age grade\n",
      "0   21     F\n",
      "1   22     F\n",
      "2   24     P\n",
      "3   25     F\n",
      "4   27     P\n",
      "______________________________\n",
      "S2\n",
      "   age grade\n",
      "5   27     P\n",
      "6   27     P\n",
      "7   35     P\n",
      "8   41     P\n",
      "\n",
      "\n",
      "Next Split with boundary 27.0\n",
      "------------------------------\n",
      "______________________________\n",
      "S1\n",
      "   age grade\n",
      "0   21     F\n",
      "1   22     F\n",
      "2   24     P\n",
      "3   25     F\n",
      "4   27     P\n",
      "5   27     P\n",
      "______________________________\n",
      "S2\n",
      "   age grade\n",
      "6   27     P\n",
      "7   35     P\n",
      "8   41     P\n",
      "\n",
      "\n",
      "Next Split with boundary 31.0\n",
      "------------------------------\n",
      "______________________________\n",
      "S1\n",
      "   age grade\n",
      "0   21     F\n",
      "1   22     F\n",
      "2   24     P\n",
      "3   25     F\n",
      "4   27     P\n",
      "5   27     P\n",
      "6   27     P\n",
      "______________________________\n",
      "S2\n",
      "   age grade\n",
      "7   35     P\n",
      "8   41     P\n",
      "\n",
      "\n",
      "Next Split with boundary 38.0\n",
      "------------------------------\n",
      "______________________________\n",
      "S1\n",
      "   age grade\n",
      "0   21     F\n",
      "1   22     F\n",
      "2   24     P\n",
      "3   25     F\n",
      "4   27     P\n",
      "5   27     P\n",
      "6   27     P\n",
      "7   35     P\n",
      "______________________________\n",
      "S2\n",
      "   age grade\n",
      "8   41     P\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# discretizes a column with respect to target column that contains the class to be classified\n",
    "# def entropy_discretize(df = None, target_column = None, discretize_column ):\n",
    "#     boundaries = calculate_boundaries(df, 'age')\n",
    "\n",
    "# split dataframe\n",
    "for x,y in enumerate(boundaries):\n",
    "    print(f\"Next Split with boundary {y}\")\n",
    "    print(\"-\" * 30)\n",
    "    print(\"_\" * 30)\n",
    "    print(\"S1\")\n",
    "    print(agey.iloc[0:x+1,:])\n",
    "    print(\"_\" * 30)\n",
    "    print(\"S2\")\n",
    "    print(agey.iloc[x+1:,:])\n",
    "    print(\"\\n\")\n",
    "\n",
    "# print(agey.iloc[0:2,:])\n",
    "# print(agey.iloc[1+1:,:])\n",
    " \n",
    "# for x,y in enumerate(agey['age']):\n",
    "#         if x == (agey['age'].size - 1):\n",
    "#             break\n",
    "#         else:\n",
    "#           print(x,x+1)\n",
    "# print(agey['age'])\n",
    "# print(calculate_boundaries(agey, 'age'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make probability function \n",
    "Entropy function\n",
    "$$\\large  ENT(S_1) = - \\sum_{i=1}^mp_ilog_2(p_i)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# probablity calculation\n",
    "# vectorized usin numpy\n",
    "def calculate_prob(column_series = None):\n",
    "    if column_series is None:\n",
    "        raise ValueError(\"Series column must not be empty\")\n",
    "    if isinstance(column_series, pd.Series) != True:\n",
    "        raise TypeError(\"Series column must be a series\")\n",
    "#     if is_string_dtype(column_series) == False and is_categorical_dtype(column_series) == False :\n",
    "#         raise TypeError(\"Series column must be of string or numerice type to be a class\")\n",
    "    total_observations = column_series.size\n",
    "    unique_counts = np.unique(column_series, return_counts = True)\n",
    "    probs = unique_counts[1] / total_observations\n",
    "    return probs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate entropy using probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    F\n",
      "1    F\n",
      "2    P\n",
      "3    F\n",
      "4    P\n",
      "5    P\n",
      "6    P\n",
      "7    P\n",
      "8    P\n",
      "Name: grade, dtype: object\n",
      "[0.33333333 0.66666667]\n",
      "0.9182958340544894\n"
     ]
    }
   ],
   "source": [
    "print(agey['grade'])\n",
    "# calculate probability of each class\n",
    "probs =  calculate_prob(agey['grade'])\n",
    "print(probs)\n",
    "entropy = stats.entropy(probs, base=2)\n",
    "print(entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def info_gain(e1,e2,s1,s2,total_size):\n",
    "    return ((s1.size/total_size) * e1) + ((s2.size/total_size) * e2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "calc entropy\n",
    "\n",
    "for each best-boundary\n",
    "split set into majorsplit\n",
    "\n",
    "for each \n",
    "\n",
    "calc boundaries\n",
    "\n",
    "split set via boundaries into set1 and set2 i.e (s1,s2,boundary)\n",
    "for each boundary:\n",
    "    find entropy of set1 and set2\n",
    "    find gain \n",
    "    store gain and boundary\n",
    "find and store best-boundary with max-gain\n",
    "check end cond (either gain of number of bins i.e best-boundaries (needs more explicit definition)\n",
    "if true terminate else continue (loop to beginning)  <-- the recursive part\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
